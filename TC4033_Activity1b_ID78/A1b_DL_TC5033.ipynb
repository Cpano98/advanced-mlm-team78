{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks\n",
    "\n",
    "#### Activity 1b: Implementing a Fully Connected Network for Kaggle ASL Dataset\n",
    "\n",
    "**Team Members #78:**\n",
    "- [Add Team Member 1 Name]\n",
    "- [Add Team Member 2 Name]\n",
    "- Carlos Pano Hernandez - A01066264\n",
    "\n",
    "#### Objective\n",
    "\n",
    "The aim of this part of the activity is to apply your understanding of Fully Connected Networks by implementing a multilayer network for the [Kaggle ASL (American Sign Language) dataset](https://www.kaggle.com/datasets/grassknoted/asl-alphabet). While you have been provided with a complete solution for a Fully Connected Network using Numpy for the MNIST dataset, you are encouraged to try to come up with the solution.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams of 3 or 4 members. Submissions from smaller or larger teams will not be accepted unless prior approval has been granted (only due to exceptional circumstances). While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Load and Preprocess Data: You are provided a starter code to load the data. Be sure to understand the code.\n",
    "\n",
    "    Review MNIST Notebook (Optional): Before diving into this activity, you have the option to revisit the MNIST example to refresh your understanding of how to build a Fully Connected Network using Numpy.\n",
    "\n",
    "    Start Fresh: Although you can refer to the MNIST solution at any point, try to implement the network for the ASL dataset on your own. This will reinforce your learning and understanding of the architecture and mathematics involved.\n",
    "\n",
    "    Implement Forward and Backward Pass: Write the code to perform the forward and backward passes, keeping in mind the specific challenges and characteristics of the ASL dataset.\n",
    "    \n",
    "     Design the Network: Create the architecture of the Fully Connected Network tailored for the ASL dataset. Choose the number of hidden layers, neurons, and hyperparameters judiciously.\n",
    "\n",
    "    Train the Model: Execute the training loop, ensuring to track performance metrics such as loss and accuracy.\n",
    "\n",
    "    Analyze and Document: Use Markdown cells to document in detail the choices you made in terms of architecture and hyperparameters, you may use figures, equations, etc to aid in your explanations. Include any metrics that help justify these choices and discuss the model's performance.  \n",
    "\n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Appropriateness of chosen architecture and hyperparameters for the ASL dataset\n",
    "    - Performance of the model on the ASL dataset (at least 70% acc)\n",
    "    - Quality of Markdown documentation\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#################################\n",
    "%matplotlib inline\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    '''\n",
    "    Split the validation set into validation and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : numpy array\n",
    "        Input features (validation set)\n",
    "    y : numpy array\n",
    "        Labels (validation set)\n",
    "    pct : float, default=0.5\n",
    "        Percentage of data to use for validation (rest goes to test)\n",
    "    shuffle : bool, default=True\n",
    "        Whether to shuffle the data before splitting\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    x_val, y_val, x_test, y_test : numpy arrays\n",
    "        Split validation and test sets\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error: x and y must have same number of samples'\n",
    "    \n",
    "    total_samples = x.shape[0]\n",
    "    val_size = int(total_samples * pct)\n",
    "    \n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_samples)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    \n",
    "    # Split the data\n",
    "    x_val = x[:val_size]\n",
    "    y_val = y[:val_size]\n",
    "    x_test = x[val_size:]\n",
    "    y_test = y[val_size:]\n",
    "    \n",
    "    return x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "### The following\n",
    "\n",
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise\n",
    "\n",
    "We normalize the data to have zero mean and unit standard deviation. This helps with training stability and convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - Mean: 0.000004, Std: 0.999999\n",
      "Validation data - Mean: 0.035683, Std: 1.007243\n",
      "Test data - Mean: 0.016821, Std: 1.003863\n"
     ]
    }
   ],
   "source": [
    "# Normalization function\n",
    "def normalise(x_mean, x_std, x_data):\n",
    "    \"\"\"\n",
    "    Normalize data to have zero mean and unit standard deviation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_mean : float\n",
    "        Mean of training data\n",
    "    x_std : float\n",
    "        Standard deviation of training data\n",
    "    x_data : numpy array\n",
    "        Data to normalize\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_data : numpy array\n",
    "        Normalized data\n",
    "    \"\"\"\n",
    "    return (x_data - x_mean) / x_std\n",
    "\n",
    "# Calculate mean and std from training data\n",
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "# Normalize all datasets using training statistics\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)\n",
    "\n",
    "# Verify normalization\n",
    "print(f\"Training data - Mean: {x_train.mean():.6f}, Std: {x_train.std():.6f}\")\n",
    "print(f\"Validation data - Mean: {x_val.mean():.6f}, Std: {x_val.std():.6f}\")\n",
    "print(f\"Test data - Mean: {x_test.mean():.6f}, Std: {x_test.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar muestras\n",
    "\n",
    "Function to visualize ASL sign images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa la letra: l\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_number(image):\n",
    "    \"\"\"\n",
    "    Plot an ASL sign image.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image : numpy array\n",
    "        Image array (28x28) to display\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display a random sample from training data\n",
    "rnd_idx = np.random.randint(len(y_train))\n",
    "print(f'La imagen muestreada representa la letra: {alphabet[y_train[rnd_idx]]}')\n",
    "plot_number(x_train[rnd_idx].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuaciones para nuestro modelo\n",
    "\n",
    "\n",
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini batches\n",
    "\n",
    "Create mini-batches for efficient training. This allows us to process data in smaller chunks, reducing memory usage and enabling gradient updates more frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle=True):\n",
    "    \"\"\"\n",
    "    Create mini-batches from the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mb_size : int\n",
    "        Size of each mini-batch\n",
    "    x : numpy array\n",
    "        Input features (num_samples, 784)\n",
    "    y : numpy array\n",
    "        Labels (num_samples,)\n",
    "    shuffle : bool, default=True\n",
    "        Whether to shuffle the data before creating batches\n",
    "    \n",
    "    Yields:\n",
    "    -------\n",
    "    (x_batch, y_batch) : tuple\n",
    "        Mini-batch of data and labels\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    \n",
    "    if shuffle:\n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "    \n",
    "    # Reshape y to (num_samples, 1) for consistency\n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom numpy array class for gradient tracking\n",
    "class np_tensor(np.ndarray):\n",
    "    \"\"\"\n",
    "    Custom numpy array subclass that allows gradient tracking.\n",
    "    This enables automatic differentiation similar to PyTorch tensors.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuestra clase Linear, ReLU y Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    \"\"\"\n",
    "    Fully connected linear layer.\n",
    "    \n",
    "    Performs the transformation: Z = WX + b\n",
    "    where W is the weight matrix and b is the bias vector.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \"\"\"\n",
    "        Initialize the linear layer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_size : int\n",
    "            Number of input features\n",
    "        output_size : int\n",
    "            Number of output features\n",
    "        \n",
    "        Uses Kaiming He initialization for weights (suitable for ReLU activation).\n",
    "        \"\"\"\n",
    "        # Kaiming He initialization: divide by sqrt(input_size/2)\n",
    "        # This helps with gradient flow when using ReLU activation\n",
    "        self.W = (np.random.randn(output_size, input_size) / np.sqrt(input_size/2)).view(np_tensor)\n",
    "        self.b = (np.zeros((output_size, 1))).view(np_tensor)\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through the linear layer.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Input data (input_size, batch_size)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Z : numpy array\n",
    "            Output (output_size, batch_size)\n",
    "        \"\"\"\n",
    "        Z = self.W @ X + self.b\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, X, Z):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradients.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Input to the layer (input_size, batch_size)\n",
    "        Z : numpy array\n",
    "            Output of the layer (output_size, batch_size)\n",
    "            Must have Z.grad attribute set from next layer\n",
    "        \"\"\"\n",
    "        # Gradient w.r.t. input X: dL/dX = W^T @ dL/dZ\n",
    "        X.grad = self.W.T @ Z.grad\n",
    "        \n",
    "        # Gradient w.r.t. weights W: dL/dW = dL/dZ @ X^T\n",
    "        self.W.grad = Z.grad @ X.T\n",
    "        \n",
    "        # Gradient w.r.t. bias b: dL/db = sum(dL/dZ, axis=1)\n",
    "        self.b.grad = np.sum(Z.grad, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    Rectified Linear Unit (ReLU) activation function.\n",
    "    \n",
    "    ReLU introduces non-linearity to the network, allowing it to learn\n",
    "    complex patterns. It's defined as: f(x) = max(0, x)\n",
    "    \"\"\"\n",
    "    def __call__(self, Z):\n",
    "        \"\"\"\n",
    "        Forward pass: apply ReLU activation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        Z : numpy array\n",
    "            Input to the activation function\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        A : numpy array\n",
    "            Activated output (same shape as Z)\n",
    "        \"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "    \n",
    "    def backward(self, Z, A):\n",
    "        \"\"\"\n",
    "        Backward pass: compute gradient of ReLU.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        Z : numpy array\n",
    "            Input to ReLU (before activation)\n",
    "        A : numpy array\n",
    "            Output of ReLU (after activation)\n",
    "            Must have A.grad attribute set from next layer\n",
    "        \n",
    "        The gradient is:\n",
    "        - dL/dZ = dL/dA where Z > 0\n",
    "        - dL/dZ = 0 where Z <= 0\n",
    "        \"\"\"\n",
    "        Z.grad = A.grad.copy()\n",
    "        Z.grad[Z <= 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_layers():\n",
    "    \"\"\"\n",
    "    Sequential container for neural network layers.\n",
    "    \n",
    "    Manages forward pass, backward pass, and parameter updates\n",
    "    for a sequence of layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers):\n",
    "        \"\"\"\n",
    "        Initialize the sequential model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        layers : list\n",
    "            List of layer objects (Linear, ReLU, etc.)\n",
    "        \"\"\"\n",
    "        self.layers = layers\n",
    "        self.x = None\n",
    "        self.outputs = {}\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        \"\"\"\n",
    "        Forward pass through all layers.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Input data (input_size, batch_size)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        output : numpy array\n",
    "            Final output after passing through all layers\n",
    "        \"\"\"\n",
    "        self.x = X\n",
    "        self.outputs['l0'] = self.x\n",
    "        \n",
    "        # Pass through each layer sequentially\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            self.x = layer(self.x)\n",
    "            self.outputs['l' + str(i)] = self.x\n",
    "        \n",
    "        return self.x\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Backward pass through all layers (backpropagation).\n",
    "        \n",
    "        Computes gradients for all parameters by propagating\n",
    "        the gradient backwards through the network.\n",
    "        \"\"\"\n",
    "        # Process layers in reverse order\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            layer = self.layers[i]\n",
    "            # Get input and output for this layer\n",
    "            layer_input = self.outputs['l' + str(i)]\n",
    "            layer_output = self.outputs['l' + str(i + 1)]\n",
    "            \n",
    "            # Call backward method of the layer\n",
    "            layer.backward(layer_input, layer_output)\n",
    "    \n",
    "    def update(self, learning_rate=1e-3):\n",
    "        \"\"\"\n",
    "        Update parameters using gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        learning_rate : float\n",
    "            Learning rate for gradient descent update\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            # Skip activation layers (they don't have parameters)\n",
    "            if isinstance(layer, ReLU):\n",
    "                continue\n",
    "            \n",
    "            # Update weights and biases: θ = θ - α * ∇θ\n",
    "            layer.W = layer.W - learning_rate * layer.W.grad\n",
    "            layer.b = layer.b - learning_rate * layer.b.grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make a prediction for a single sample.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : numpy array\n",
    "            Input sample (input_size, 1)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        prediction : int\n",
    "            Predicted class index\n",
    "        \"\"\"\n",
    "        return np.argmax(self.__call__(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmaxXEntropy(x, y):\n",
    "    \"\"\"\n",
    "    Compute softmax probabilities and cross-entropy loss.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : numpy array\n",
    "        Raw scores from the network (num_classes, batch_size)\n",
    "    y : numpy array\n",
    "        True labels (batch_size, 1)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    preds : numpy array\n",
    "        Predicted probabilities (num_classes, batch_size)\n",
    "    cost : float\n",
    "        Average cross-entropy loss\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[1]\n",
    "    \n",
    "    # Compute softmax: exp(x) / sum(exp(x))\n",
    "    # Subtract max for numerical stability\n",
    "    x_shifted = x - np.max(x, axis=0, keepdims=True)\n",
    "    exp_scores = np.exp(x_shifted)\n",
    "    probs = exp_scores / exp_scores.sum(axis=0, keepdims=True)\n",
    "    preds = probs.copy()\n",
    "    \n",
    "    # Compute cross-entropy loss: -log(p_true_class)\n",
    "    # Get probability of true class for each sample\n",
    "    y_hat = probs[y.squeeze(), np.arange(batch_size)]\n",
    "    cost = np.sum(-np.log(y_hat + 1e-8)) / batch_size  # Add small epsilon for numerical stability\n",
    "    \n",
    "    # Compute gradient: dL/dx = probs - one_hot(y)\n",
    "    # For the true class, subtract 1; others remain as is\n",
    "    probs[y.squeeze(), np.arange(batch_size)] -= 1\n",
    "    x.grad = probs.copy()\n",
    "    \n",
    "    return preds, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    \"\"\"\n",
    "    Compute accuracy of the model on a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : Sequential_layers\n",
    "        Trained model\n",
    "    x : numpy array\n",
    "        Input features (num_samples, 784)\n",
    "    y : numpy array\n",
    "        True labels (num_samples, 1) or (num_samples,)\n",
    "    mb_size : int\n",
    "        Mini-batch size\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    acc : float\n",
    "        Accuracy (0-1)\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Reshape y if needed\n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    for x_batch, y_batch in create_minibatches(mb_size, x, y, shuffle=False):\n",
    "        # Forward pass: transpose to (784, batch_size)\n",
    "        pred = model(x_batch.T.view(np_tensor))\n",
    "        # Get predicted class (argmax along class dimension)\n",
    "        pred_classes = np.argmax(pred, axis=0)\n",
    "        # Compare with true labels\n",
    "        correct += np.sum(pred_classes == y_batch.squeeze())\n",
    "        total += pred.shape[1]\n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def train(model, epochs, mb_size=128, learning_rate=1e-3):\n",
    "    \"\"\"\n",
    "    Train the neural network model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : Sequential_layers\n",
    "        Model to train\n",
    "    epochs : int\n",
    "        Number of training epochs\n",
    "    mb_size : int\n",
    "        Mini-batch size\n",
    "    learning_rate : float\n",
    "        Learning rate for gradient descent\n",
    "    \"\"\"\n",
    "    # Reshape y_train if needed\n",
    "    y_train_reshaped = y_train.reshape(-1, 1) if len(y_train.shape) == 1 else y_train\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Iterate through mini-batches\n",
    "        for x_batch, y_batch in create_minibatches(mb_size, x_train, y_train_reshaped):\n",
    "            # Forward pass: transpose input to (784, batch_size)\n",
    "            scores = model(x_batch.T.view(np_tensor))\n",
    "            \n",
    "            # Compute loss and gradients\n",
    "            _, cost = softmaxXEntropy(scores, y_batch)\n",
    "            \n",
    "            # Backward pass: compute gradients\n",
    "            model.backward()\n",
    "            \n",
    "            # Update parameters\n",
    "            model.update(learning_rate)\n",
    "        \n",
    "        # Print progress after each epoch\n",
    "        val_acc = accuracy(model, x_val, y_val, mb_size)\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Cost: {cost:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    print(f'\\nTraining completed!')\n",
    "    print(f'Final validation accuracy: {accuracy(model, x_val, y_val, mb_size):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your model and train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "  Input: 784 neurons\n",
      "  Hidden Layer 1: 256 neurons + ReLU\n",
      "  Hidden Layer 2: 128 neurons + ReLU\n",
      "  Output: 24 neurons (ASL letters)\n",
      "\n",
      "Training Parameters:\n",
      "  Mini-batch size: 256\n",
      "  Learning rate: 0.001\n",
      "  Epochs: 30\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/30 - Cost: 0.0647, Validation Accuracy: 0.7619\n",
      "Epoch 2/30 - Cost: 0.0135, Validation Accuracy: 0.7872\n",
      "Epoch 3/30 - Cost: 0.0078, Validation Accuracy: 0.7909\n",
      "Epoch 4/30 - Cost: 0.0036, Validation Accuracy: 0.7889\n",
      "Epoch 5/30 - Cost: 0.0048, Validation Accuracy: 0.7914\n",
      "Epoch 6/30 - Cost: 0.0030, Validation Accuracy: 0.7922\n",
      "Epoch 7/30 - Cost: 0.0027, Validation Accuracy: 0.7959\n",
      "Epoch 8/30 - Cost: 0.0027, Validation Accuracy: 0.7948\n",
      "Epoch 9/30 - Cost: 0.0023, Validation Accuracy: 0.7967\n",
      "Epoch 10/30 - Cost: 0.0021, Validation Accuracy: 0.7973\n",
      "Epoch 11/30 - Cost: 0.0023, Validation Accuracy: 0.7967\n",
      "Epoch 12/30 - Cost: 0.0017, Validation Accuracy: 0.7987\n",
      "Epoch 13/30 - Cost: 0.0014, Validation Accuracy: 0.7978\n",
      "Epoch 14/30 - Cost: 0.0012, Validation Accuracy: 0.7989\n",
      "Epoch 15/30 - Cost: 0.0016, Validation Accuracy: 0.7978\n",
      "Epoch 16/30 - Cost: 0.0011, Validation Accuracy: 0.7978\n",
      "Epoch 17/30 - Cost: 0.0008, Validation Accuracy: 0.7981\n",
      "Epoch 18/30 - Cost: 0.0010, Validation Accuracy: 0.7987\n",
      "Epoch 19/30 - Cost: 0.0009, Validation Accuracy: 0.7995\n",
      "Epoch 20/30 - Cost: 0.0009, Validation Accuracy: 0.7964\n",
      "Epoch 21/30 - Cost: 0.0006, Validation Accuracy: 0.7978\n",
      "Epoch 22/30 - Cost: 0.0013, Validation Accuracy: 0.7964\n",
      "Epoch 23/30 - Cost: 0.0007, Validation Accuracy: 0.7956\n",
      "Epoch 24/30 - Cost: 0.0005, Validation Accuracy: 0.7970\n",
      "Epoch 25/30 - Cost: 0.0005, Validation Accuracy: 0.7978\n",
      "Epoch 26/30 - Cost: 0.0006, Validation Accuracy: 0.7975\n",
      "Epoch 27/30 - Cost: 0.0007, Validation Accuracy: 0.7973\n",
      "Epoch 28/30 - Cost: 0.0009, Validation Accuracy: 0.7973\n",
      "Epoch 29/30 - Cost: 0.0005, Validation Accuracy: 0.7967\n",
      "Epoch 30/30 - Cost: 0.0004, Validation Accuracy: 0.7964\n",
      "\n",
      "Training completed!\n",
      "Final validation accuracy: 0.7964\n"
     ]
    }
   ],
   "source": [
    "# Create the model architecture\n",
    "# Input: 784 (28x28 flattened image)\n",
    "# Hidden Layer 1: 256 neurons\n",
    "# Hidden Layer 2: 128 neurons\n",
    "# Output: 24 classes (ASL letters a-z excluding j and z)\n",
    "\n",
    "model = Sequential_layers([\n",
    "    Linear(784, 256),  # First hidden layer\n",
    "    ReLU(),            # Activation\n",
    "    Linear(256, 128),  # Second hidden layer\n",
    "    ReLU(),            # Activation\n",
    "    Linear(128, 24)    # Output layer (24 ASL letters)\n",
    "])\n",
    "\n",
    "# Training hyperparameters\n",
    "mb_size = 256\n",
    "learning_rate = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"  Input: 784 neurons\")\n",
    "print(f\"  Hidden Layer 1: 256 neurons + ReLU\")\n",
    "print(f\"  Hidden Layer 2: 128 neurons + ReLU\")\n",
    "print(f\"  Output: 24 neurons (ASL letters)\")\n",
    "print(f\"\\nTraining Parameters:\")\n",
    "print(f\"  Mini-batch size: {mb_size}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"\\nStarting training...\\n\")\n",
    "\n",
    "# Train the model\n",
    "train(model, epochs, mb_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Architecture Design\n",
    "\n",
    "For the ASL dataset, we design a fully connected neural network with the following architecture:\n",
    "\n",
    "**Network Architecture:**\n",
    "- **Input Layer:** 784 neurons (28×28 flattened images)\n",
    "- **Hidden Layer 1:** 256 neurons with ReLU activation\n",
    "- **Hidden Layer 2:** 128 neurons with ReLU activation  \n",
    "- **Output Layer:** 24 neurons (one for each ASL letter: a-z excluding j and z)\n",
    "\n",
    "**Rationale:**\n",
    "1. **Input Size (784):** ASL images are 28×28 pixels, same as MNIST\n",
    "2. **Hidden Layers:** Two hidden layers provide sufficient capacity to learn complex patterns in sign language gestures\n",
    "3. **Layer Sizes:** Starting with 256 and reducing to 128 allows the network to learn hierarchical features while controlling model complexity\n",
    "4. **Output Size (24):** ASL alphabet has 24 classes (26 letters minus j and z, which require motion)\n",
    "\n",
    "**Hyperparameters:**\n",
    "- **Mini-batch Size:** 256 - Balances memory usage and gradient stability\n",
    "- **Learning Rate:** 1e-3 - Standard learning rate for SGD, provides stable convergence\n",
    "- **Epochs:** 30 - Sufficient to achieve good performance without overfitting\n",
    "- **Initialization:** Kaiming He initialization for ReLU layers\n",
    "\n",
    "**Expected Performance:** \n",
    "- Target: ≥70% accuracy (assignment requirement)\n",
    "- Expected: ~75-85% accuracy based on similar architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your model on Random data from your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 5 random samples:\n",
      "\n",
      "Sample 1:\n",
      "  Predicted: m | True: m ✓\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 2:\n",
      "  Predicted: e | True: e ✓\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 3:\n",
      "  Predicted: s | True: s ✓\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 4:\n",
      "  Predicted: c | True: c ✓\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 5:\n",
      "  Predicted: m | True: m ✓\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on a few random samples\n",
    "num_samples = 5\n",
    "print(f\"Testing on {num_samples} random samples:\\n\")\n",
    "\n",
    "for i in range(num_samples):\n",
    "    idx = np.random.randint(len(y_test))\n",
    "    \n",
    "    # Get prediction\n",
    "    pred = model.predict(x_test[idx].reshape(-1, 1))\n",
    "    true_label = y_test[idx]\n",
    "    \n",
    "    # Display result\n",
    "    is_correct = \"✓\" if pred == true_label else \"✗\"\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Predicted: {alphabet[pred]} | True: {alphabet[true_label]} {is_correct}\")\n",
    "    \n",
    "    # Plot the image\n",
    "    plot_number(x_test[idx].reshape(28, 28))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance\n",
    "\n",
    "Let's evaluate the model on the test set to see the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8026 (80.26%)\n",
      "✓ Requirement met! Accuracy ≥ 70%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_accuracy = accuracy(model, x_test, y_test, mb_size)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Check if we met the requirement\n",
    "if test_accuracy >= 0.70:\n",
    "    print(f\"✓ Requirement met! Accuracy ≥ 70%\")\n",
    "else:\n",
    "    print(f\"✗ Requirement not met. Need ≥ 70% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "**Final Results:**\n",
    "- **Test Accuracy:** [Will be displayed after training]\n",
    "- **Validation Accuracy:** [Will be displayed during training]\n",
    "\n",
    "### Model Performance Discussion\n",
    "\n",
    "**Architecture Choices:**\n",
    "1. **Two Hidden Layers:** This depth allows the network to learn hierarchical features:\n",
    "   - First layer (256 neurons) captures low-level features (edges, shapes)\n",
    "   - Second layer (128 neurons) combines these into higher-level patterns (hand configurations)\n",
    "   - Output layer makes the final classification decision\n",
    "\n",
    "2. **Layer Sizes:** The decreasing size (256 → 128 → 24) follows a common pattern in deep learning:\n",
    "   - Larger first hidden layer provides capacity for feature extraction\n",
    "   - Smaller second layer helps with generalization and reduces overfitting\n",
    "   - Output size matches the number of classes (24 ASL letters)\n",
    "\n",
    "3. **ReLU Activation:** \n",
    "   - Introduces non-linearity essential for learning complex patterns\n",
    "   - Helps with gradient flow during backpropagation\n",
    "   - Computationally efficient\n",
    "\n",
    "**Hyperparameter Justification:**\n",
    "- **Mini-batch Size (256):** Provides stable gradient estimates while maintaining reasonable training speed\n",
    "- **Learning Rate (1e-3):** Standard choice that balances convergence speed and stability\n",
    "- **Epochs (30):** Sufficient to learn the patterns without excessive overfitting\n",
    "\n",
    "**Challenges Encountered:**\n",
    "1. **Class Imbalance:** Some ASL letters may be more common than others in the dataset\n",
    "2. **Similar Gestures:** Some letters have similar hand shapes, making them harder to distinguish\n",
    "3. **Normalization:** Proper normalization was crucial for training stability\n",
    "\n",
    "**Potential Improvements:**\n",
    "1. **Learning Rate Scheduling:** Could implement learning rate decay for better convergence\n",
    "2. **Regularization:** Add dropout or L2 regularization to reduce overfitting\n",
    "3. **Data Augmentation:** Rotate, shift, or scale images to increase dataset diversity\n",
    "4. **Architecture Tuning:** Experiment with different layer sizes and depths\n",
    "5. **Batch Normalization:** Could help with training stability and convergence speed\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The implemented fully connected neural network successfully classifies ASL sign language images using only NumPy. The architecture demonstrates understanding of:\n",
    "- Forward and backward propagation\n",
    "- Gradient computation and parameter updates\n",
    "- Activation functions and their derivatives\n",
    "- Loss functions for multi-class classification\n",
    "\n",
    "The model achieves the required ≥70% accuracy on the ASL dataset, demonstrating successful application of deep learning fundamentals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
